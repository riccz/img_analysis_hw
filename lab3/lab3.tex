\documentclass[a4paper,oneside]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage[margin=2.54cm]{geometry}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{siunitx}
\usepackage{hyperref}
\usepackage{color}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[section]{placeins}
\usepackage[backend=biber,style=ieee]{biblatex}

\usepackage{customcmds}
\usepackage{codecmds}

\addbibresource{lab3.bib}

\DeclareMathOperator{\clip}{clip}

\author{Riccardo Zanol}
\title{Laboratory 3}

\begin{document}
\matlabcodeconfig
\maketitle
\section*{Experiment 1}
\stepcounter{section}
The purpose of first part of this homework is to implement two
demosaicing algorithms and test them, together with the one
implemented in Matlab, on the eight images \inlinecode{kodimXX.png}
to compare their performances, visually and using the mean squared
error in the CIELAB color space.

Each one of the test images is downsampled by the provided function
\inlinecode{create_bayer} according to the GRBG Bayer mask (see
Fig.~\ref{fig:bayer_grbg}), in order to simulate the kind of data that
would be acquired by a single-sensor imaging system,
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.66\textwidth]{include_imgs/bayer_grbg}
    \caption{GRBG}
    \label{fig:bayer_grbg}
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=0.66\textwidth]{include_imgs/bayer_rggb}
    \caption{RGGB}
    \label{fig:bayer_rggb}
  \end{subfigure}
  \caption{The two Bayer CFA patterns used in this homework}
\end{figure}
and is then demosaiced using three of the algorithms described in
\cite{demosaic_alg}: the linear interpolation, the gradient-corrected
linear interpolation and a combination of the pattern recognition
interpolation and the smooth hue transition interpolation.

\subsection{Linear interpolation}
\label{sec:linear}
The linear interpolation algorithm is the simplest of the three, it
just sets the missing color components of each pixel to their means in
a 3~by~3 window around the pixel.
%
As an example, in Fig.~\ref{fig:bayer_neigh}, the color of the central
pixel is set to
\begin{align*}
  R_5 &= R_5 \\
  G_5 &= \frac{1}{4}\left( G_2 + G_4 + G_6 + G_8 \right) \\
  B_5 &= \frac{1}{4}\left( B_1 + B_3 + B_7 + B_9 \right) .
\end{align*}
When the algorithm computes the means of the red and blue components
around a green pixel, e.g.~$R_6$~and~$B_6$ in
Fig.~\ref{fig:bayer_neigh}, it takes into account only the two pixels
of the corresponding color that are present in the 3~by~3 window so
\begin{equation*}
  B_6 = \frac{1}{2} \left( B_3 + B_9 \right)
\end{equation*}
and $R_6$ is the mean between $R_5$ and the value at the right of
pixel~6.
%
The same thing also occurs near the picture borders, where there are
only three or two pixels to interpolate the green values and just two
or one pixel to interpolate the other colors.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.20\textwidth]{include_imgs/bayer_neigh}
  \caption{Neighborhood of a red pixel in a Bayer pattern}
  \label{fig:bayer_neigh}
\end{figure}

This algorithm is implemented by the function
\inlinecode{demosaic_linear} and the output images are saved as
\inlinecode{demosaic_kodimXX.png}.

\subsection{Gradient-corrected linear interpolation}
The gradient-corrected linear interpolation is a more complex
algorithm, described in detail in \cite{demosaic_gradient}, that
exploits the correlation between the color components to improve the
quality of the demosaiced image.
%
The mean values of the neighbors, $\hat{r}_{lin}$, $\hat{g}_{lin}$ and
$\hat{b}_{lin}$ computed like in the previous algorithm, are corrected
using the gradient of the color that was measured at that location:
\begin{align*}
  \hat{g}(i,j) &= \hat{g}_{lin}(i,j) + \alpha \Delta_R(i,j) & & \text{red pixel location} \\
  \hat{g}(i,j) &= \hat{g}_{lin}(i,j) + \alpha \Delta_B(i,j) & & \text{blue pixel location} \\
  %
  \hat{r}(i,j) &= \hat{r}_{lin}(i,j) + \beta \Delta_G(i,j) & & \text{green pixel location} \\
  \hat{r}(i,j) &= \hat{r}_{lin}(i,j) + \beta \Delta_B(i,j) & & \text{blue pixel location} \\
  %
  \hat{b}(i,j) &= \hat{b}_{lin}(i,j) + \gamma \Delta_G(i,j) & & \text{green pixel location} \\
  \hat{b}(i,j) &= \hat{b}_{lin}(i,j) + \gamma \Delta_R(i,j) & & \text{red pixel location} \\
\end{align*}
where the gradients are computed on a 5~by~5 window around the pixel
at position $(i,j)$ using a mask that depends on the location and on
the color component that is being interpolated. As an example, when
the green value is interpolated at the location of a red pixel, the
gradient is computed as:
\begin{equation*}
  \Delta_R(i,j) \triangleq r(i,j) - \frac{1}{4} \sum_{(m,n)} r(i+m,j+n)
  \qquad (m,n) \in \{(0,-2), (0,2), (-2,0), (2,0)\} .
\end{equation*}
The gradient-correction gains are chosen in order to minimize the mean
squared error given the statistics of an image set (which contains the
test images used in this homework) and they are approximated to
multiples of small powers of $1/2$: $\alpha = 1/2$, $\beta = 5/8$ and
$\gamma = 3/4$. In \cite{demosaic_gradient} the eight possible masks
for the computation of the gradient are scaled by the
gradient-correction gains and substituted in the six equations above
to obtain eight linear FIR filters to apply to the image.

This algorithm is the one implemented by the built-in Matlab function
\inlinecode{demosaic} and the output images are saved as
\inlinecode{matlab_demosaic_kodimXX.png}.

\subsection{Pattern recognition and smooth hue transition interpolation}
Another demosaicing algorithm described briefly in \cite{demosaic_alg}
and in more detail in \cite{demosaic_army} is the pattern recognition
interpolation, which classifies the pixels into edges, corners and
stripes according to their neighborhood and applies different
interpolation rules for each kind of point.
%
It considers the four neighbors of each missing green pixel and
computes their mean, then labels each neighbor as either ``low'', when
its value is smaller than the mean, or ``high'' otherwise.
%
These labels are used to classify the missing pixel in one of the
categories mentioned above:
\begin{itemize}
\item if three neighbors share the same label the pixel is part of an
  edge (see Fig.s \ref{fig:lowedge} and \ref{fig:highedge}),
\item if two adjacent neighbors share the same label the pixel is part
  of a corner (see Fig. \ref{fig:corner}),
\item
  if two opposite neighbors share the same label the pixel is part of
  a stripe (see Fig. \ref{fig:stripe}).
\item The only missing case, four neighbors with the same intensity, is
  handled like an edge by the code because, as will be seen in the
  next paragraph, this will give the interpolated pixel the median
  value of its neighbors (and so their same value).
\end{itemize}
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.2\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{include_imgs/pri_corner}
    \caption{Corner}
    \label{fig:corner}
  \end{subfigure}%
  \begin{subfigure}{0.2\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{include_imgs/pri_lowedge}
    \caption{Low edge}
    \label{fig:lowedge}
  \end{subfigure}%
  \begin{subfigure}{0.2\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{include_imgs/pri_highedge}
    \caption{High edge}
    \label{fig:highedge}
  \end{subfigure}%
  \begin{subfigure}{0.2\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{include_imgs/pri_stripe}
    \caption{Stripe}
    \label{fig:stripe}
  \end{subfigure}
  \caption{Example of classification done by the pattern recognition
    interpolation algorithm}
\end{figure}

After the pixels have been classified, the pattern recognition
algorithm sets their value according to their class:
\begin{itemize}
\item Edge points of both kinds are given the median value of their
  neighbors,
  \item Corner points are given the value $G = \clip_C^B(2M-S)$ where
    $S$ is the mean value of the pixels labeled ``X'' in
    Fig. \ref{fig:mask_corner},
    \item Stripe points are given the value $G = \clip_C^B(2M-S)$ where
    $S$ is the mean value of the pixels labeled ``X'' in
    Fig. \ref{fig:mask_stripe}.
\end{itemize}
In both the stripe and the corner cases above $M$ is the median of the
four closest neighbors, $B$ and $C$ are the values of the second and
the third neighbors taken in descending order ($A \geq B \geq C \geq
D$) and the $\clip$ function is defined as:
\begin{equation*}
  \clip_C^B(x) = \begin{cases}
    B \qquad & x > B \\
    x \qquad & C \leq x \leq B \\
    C \qquad & x < C
    \end{cases} .
\end{equation*}
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{include_imgs/pri_corner_mask}
    \caption{Corner}
    \label{fig:mask_corner}
  \end{subfigure}%
  \begin{subfigure}{0.33\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{include_imgs/pri_stripe_mask}
    \caption{Stripe}
    \label{fig:mask_stripe}
  \end{subfigure}
  \caption{Masks used in the computation of the interpolated value}
\end{figure}

There is no mention on \cite{demosaic_alg, demosaic_army} on what the
algorithm should do near the picture border, when there are not enough
neighbors, however this is just a small two-pixel border so it should
not affect the performances so much.
%
If the four closest neighbors are not available the pixel cannot be
classified so the code uses the same linear interpolation algorithm of
section \ref{sec:linear}.
%
When, instead, the pixel can be classified but the ``X'' pixels of
Fig.s \ref{fig:mask_corner} and \ref{fig:mask_stripe} are not all
available, the mean $S$ is computed using only the ones that fall
inside the picture.

This algorithm is designed to work only on the green component so, in
order to perform a complete demosaicing of an image, another algorithm
must be used to demosaic the other colors. A suggestion given by
\cite{demosaic_alg, demosaic_army} is to use the smooth hue transition
interpolation algorithm, which assumes that the hue changes smoothly
across an object's surface and so it uses the ratio between the blue
or red components and the green component instead of their absolute
values.


\subsection{Comparison}
After having being demosaiced by each one of the two algorithms the
images are converted into the CIELAB color space to allow them to be
compared to the original images and the mean squared error of the two
algorithms is calculated. The MSE is computed by taking the distance
between each pixel and averaging:
\begin{align*}
  d(i,j) &= \sqrt{\sum_{k=1}^3 \left(A(i,j,k) - B(i,j,k)\right)^2 } \\
  \text{MSE} &= \frac{1}{WH}\sum_{i=0}^H\sum_{j=0}^Wd(i,j)
\end{align*}
where $A(i,j,1) = L(i,j)$, $A(i,j,2) = a(i,j)$ and $A(i,j,3) = b(i,j)$
are the three coordinates in the CIELAB space of the pixel $(i,j)$ of
image $A$. A two pixels wide border is excluded from the comparison
because the function \inlinecode{demosaic_linear} does not perform the
interpolation in this region.  The computed values of the MSE are
shown in Tab.~\ref{tab:mse} where it can be seen that the gradient
correction should improve a lot the quality of the interpolation,
since it halves the MSE.
\begin{table}[h]
  \centering
  \begin{tabular}{IRRR}
    \multicolumn{1}{c}{Image} &
    \multicolumn{1}{c}{Linear} &
    \multicolumn{1}{c}{Gradient-corrected} &
    \multicolumn{1}{c}{PRI and SHTI} \\
    \hline
    kodim01.png & 5.053 & 2.909 & 3.434 \\
    kodim05.png & 4.637 & 2.407 & 3.242 \\
    kodim13.png & 6.275 & 3.707 & 4.850 \\
    kodim19.png & 3.333 & 1.974 & 2.236 \\
  \end{tabular}
  \caption{Mean squared error of the demosaicing algorithms}
  \label{tab:mse}
\end{table}
Unfortunately this is not the case as the gradient correction does
improve a little bit the quality of the reconstructed images, but it
still leaves a lot of noticeable artifacts close to edges and small
details. For example in the detail of image \inlinecode{kodim_19.png},
where both algorithms obtain the smallest value of the MSE, shown in
Fig.~\ref{fig:artifact} there are some colored vertical streaks on the
white fence that are the result of the interpolation.
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{demosaic_kodim19_artifact}
  \caption{\inlinecode{demosaic_linear}}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{matlab_demosaic_kodim19_artifact}
  \caption{\inlinecode{demosaic}}
\end{subfigure}
\caption{Detail of \inlinecode{kodim_19.png} after the demosaicing}
\label{fig:artifact}
\end{figure}

\section*{Experiment 2}
The matlab script \inlinecode{ex2.m} applies the same two demosaicing
algorithms to some images acquired from a reflex camera. This time,
since it starts from the raw sensor data, it has to perform some
additional steps to get an output that can be compared to the JPEG
files produced by the camera. The script reads the DNG files using the
provided function \inlinecode{read_dng}, which also performs the
linearization and white balancing of the image using the meta-data
stored with it, then it applies the same two demosaicing algorithms
of experiment 1.

The raw data of the image is stored according to a ``RGGB'' Bayer
pattern so the script adds one column of zeros at the beginning and at
the end of the image, in this way it shifts the pattern horizontally
by one pixel and it becomes the ``GRBG'' pattern that the function
\inlinecode{demosaic_linear} expects. The extra columns do not affect
the demosaicing results because this function skips a two pixel wide
border around the image.  The built-in \inlinecode{demosaic} function
could work directly on the ``RGGB'' pattern, but since the two columns
must be added anyway the script uses it in the same way of experiment
1. This function also requires the input pixels to be of type
\inlinecode{uint8} so the image is converted before the demosaicing.

After the demosaicing step, the image is post-processed with the
provided \inlinecode{post_process} function that normalizes the image
intensity and applies a gamma correction.

Comparing the results with the JPEG files produced by the camera it
can be seen that the steps that are skipped in the raw image processing
affect the color, in particular the \inlinecode{post_process} function
does not convert the image from the color space of the camera to
sRGB. As can be seen in Fig.~\ref{fig:chart} the result images appear
to have a much lower contrast than the camera JPEG file.
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.95\linewidth]{demosaic_macbeth_color_small}
  \caption{\inlinecode{demosaic_linear}}
\end{subfigure}%
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.95\linewidth]{matlab_demosaic_macbeth_color_small}
  \caption{\inlinecode{demosaic}}
\end{subfigure}%
  \begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.95\linewidth]{camera_macbeth_color_small}
  \caption{JPEG from the camera}
\end{subfigure}
\caption{Comparison of the color chart}
\label{fig:chart}
\end{figure}
The demosaicing performed by the matlab script also leaves a lot of
artifacts, especially in the dark areas as can be seen from
Fig.~\ref{fig:dark_artifacts}. In this case the linear interpolation
algorithm appears to produce slightly better images than the gradient
corrected one, but they are both very noisy compared to the camera's
processed images.
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.95\linewidth]{demosaic_students2_detail}
  \caption{\inlinecode{demosaic_linear}}
\end{subfigure}%
\begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.95\linewidth]{matlab_demosaic_students2_detail}
  \caption{\inlinecode{demosaic}}
\end{subfigure}%
  \begin{subfigure}{.33\textwidth}
  \centering
  \includegraphics[width=.95\linewidth]{camera_students2_detail}
  \caption{JPEG from the camera}
\end{subfigure}
\caption{Comparison of a detail from \inlinecode{students2.dng}}
\label{fig:dark_artifacts}
\end{figure}

\printbibliography
\end{document}
